}
priorList <- list(betaPrior = betaPrior,
rateEPrior = rateEPrior,
iddParamsPrior = iddParamsPrior)
initsList <- list(beta = betaInit,
rateE = rateEInit,
iddParams = iddParamsInit)
# run three chains in parallel
cl <- makeCluster(3)
clusterExport(cl, list('datList',  'X', 'initsList',
'priorList', 'iddFun_i', 'maxInf_i'))
resThree <- parLapplyLB(cl, 1:3, function(x) {
library(BayesSEIR)
# MCMC specifications
niter <- 5000
nburn <- 200
set.seed(x)
mcmcSEIR(dat = datList, X = X,
inits = initsList,
niter = niter, nburn = nburn,
infPeriodSpec = 'IDD',
priors = priorList,
iddFun = iddFun_i, maxInf = maxInf_i,
EKnown = TRUE)
})
stopCluster(cl)
### Get Gelman Rubin Diagnostic
# sample drawn from every 100th observation post burnin
idxKeep <- seq(1, nrow(resThree[[1]]), 100)
paramSamples1 <- resThree[[1]][idxKeep,]
paramSamples2 <- resThree[[2]][idxKeep,]
paramSamples3 <- resThree[[3]][idxKeep,]
res_mcmc <- mcmc.list(mcmc(paramSamples1),
mcmc(paramSamples2),
mcmc(paramSamples3))
gdiag <- data.frame(gelman.diag(res_mcmc, multivariate = F)$psrf)
colnames(gdiag) <- c('gr', 'grUpper')
allConverge <- all(gdiag$gr < 1.1)
### Get posterior median IDD curve pre-intervention
paramsPost <- rbind(paramSamples1, paramSamples2, paramSamples3)
iddParamsPost <- paramsPost[,-grep('beta1|beta2|rateE', colnames(paramsPost))]
beta1Post <- paramsPost[,grep('beta1', colnames(paramsPost))]
iddCurveFun <- get(iddFun_i)
p0SE <- matrix(NA, nrow = maxInf_i, ncol = nrow(paramsPost))
for (j in 1:nrow(paramsPost)) {
if (iddFun_i == 'splineIDD') {
iddCurve <- iddCurveFun(1:maxInf_i,
params = list(iddParamsPost[j,]),
XBasis = initsList$iddParams$XBasis)
} else {
iddCurve <- iddCurveFun(1:maxInf_i,
params = list(iddParamsPost[j,]))
}
p0SE[,j] <- 1 - exp(-exp(beta1Post[j]) * iddCurve /N)
}
curveMedian <- apply(p0SE, 1, median)
curveCI <- apply(p0SE, 1, quantile, probs = c(0.025, 0.975))
iddSummary <- data.frame(iddFun = iddFun_i,
simNumber = simNumber_i,
maxInf = maxInf_i,
datGen = datGen_i,
infDay = 1:maxInf_i,
iddCurveMedian = curveMedian,
iddCurveLower = curveCI[1,],
iddCurveUpper = curveCI[1,],
allConverge = allConverge)
# concatenate results across batches for output
if (i == batchIdx[1]) {
batchOutput <- iddSummary
} else {
batchOutput <- rbind.data.frame(batchOutput, iddSummary)
}
} # end loop
resThree
iddCurve
j
iddCurveFun
head(iddParamsPost)
iddParamsPost[j,]
list(iddParamsPost[j,])
as.list(iddParamsPost[j,])
setwd("K:/IDD_Paper/simulation_study")
idx <- 1
### load libraries
library(parallel)
library(coda)
library(splines)
library(BayesSEIR)
source('../helper_functions.R')
# create data frame of all possible models to be fit
maxInfs <- c(15, 20)
nSim <- 100
modelsGamma <- expand.grid(iddFun = 'dgammaIDD',
simNumber = 1:nSim,
maxInf = maxInfs,
datGen = c('IDD_peak', 'IDD_exp'),
stringsAsFactors = FALSE)
modelsLognormal <- expand.grid(iddFun = 'dlnormIDD',
simNumber = 1:nSim,
maxInf = maxInfs,
datGen = c('IDD_peak', 'IDD_exp'),
stringsAsFactors = FALSE)
modelsLogit <- expand.grid(iddFun = 'logitIDD',
simNumber = 1:nSim,
maxInf = maxInfs,
datGen = 'IDD_logit',
stringsAsFactors = FALSE)
modelsSpline <- expand.grid(iddFun = 'splineIDD',
simNumber = 1:nSim,
maxInf = maxInfs,
datGen = c('IDD_peak', 'IDD_exp', 'IDD_logit'),
stringsAsFactors = FALSE)
# 1600 models to be fit
allModels <- rbind.data.frame(modelsGamma,
modelsLognormal,
modelsLogit,
modelsSpline)
# model specifications that are the same for all models
N <- 5363500
E0 <- 1
I0 <- 0
S0 <- N - E0 - I0
# intervention time
tstar <- 120
# fit models in batches of 100 (16 batches total)
# each batch is one model/data generation scenario
batchSize <- 100
batchIdx <- batchSize * (idx - 1) + 1:batchSize
for (i in batchIdx) {
iddFun_i <- allModels$iddFun[i]
simNumber_i <- allModels$simNumber[i]
maxInf_i <- allModels$maxInf[i]
datGen_i <- allModels$datGen[i]
print(paste0('IDD Fun: ', iddFun_i,
', data gen: ', datGen_i,
', max inf: ', maxInf_i,
', sim number: ', simNumber_i))
############################################################################
### set up data
# load data
dat <- readRDS(paste0('data/', datGen_i, '_data.rds'))
# extract data for simulation of interest
Istar <- dat$Istar[,simNumber_i]
Estar <- dat$Estar[,simNumber_i]
# trim/add to Istar and Estar in the case of excess 0's
fullTime <- length(Istar)
lastInfTime <- max(which(Istar > 0))
if (lastInfTime + maxInf_i <= fullTime) {
newTime <- lastInfTime + maxInf_i
Istar <- Istar[1:newTime]
Estar <- Estar[1:newTime]
} else {
zerosAdd <- lastInfTime + maxInf_i - fullTime
Istar <- c(Istar, rep(0, zerosAdd))
Estar <- c(Estar, rep(0, zerosAdd))
newTime <- length(Istar)
}
